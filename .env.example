# ==============================================================================
# GEETANJALI CONFIGURATION
# ==============================================================================
# Copy this file to .env and update with your values.
#
# This single .env file is used by:
#   - Docker Compose (all services)
#   - Backend (Python/FastAPI via pydantic-settings)
#   - Frontend (React/Vite - VITE_* variables only)
#
# ==============================================================================
# QUICK START - Choose your mode:
# ==============================================================================
#
#   MOCK MODE (UI development - no API costs, instant responses):
#     USE_MOCK_LLM=true
#
#   ANTHROPIC MODE (production):
#     USE_MOCK_LLM=false
#     LLM_PROVIDER=anthropic
#     ANTHROPIC_API_KEY=sk-ant-...
#
#   OLLAMA MODE (local LLM):
#     USE_MOCK_LLM=false
#     LLM_PROVIDER=ollama
#     OLLAMA_ENABLED=true
#
# ==============================================================================


# ------------------------------------------------------------------------------
# DATABASE
# ------------------------------------------------------------------------------
# Docker Compose uses POSTGRES_* variables
POSTGRES_DB=geetanjali
POSTGRES_USER=geetanjali
POSTGRES_PASSWORD=geetanjali_dev_pass

# Backend uses DATABASE_URL (localhost for local dev, postgres for Docker)
DATABASE_URL=postgresql://geetanjali:geetanjali_dev_pass@localhost:5432/geetanjali


# ------------------------------------------------------------------------------
# REDIS (Cache)
# ------------------------------------------------------------------------------
REDIS_PASSWORD=redis_dev_pass
# Backend uses REDIS_URL (localhost for local dev, redis for Docker)
REDIS_URL=redis://:redis_dev_pass@localhost:6379/0


# ------------------------------------------------------------------------------
# LLM PROVIDER
# ------------------------------------------------------------------------------
# Provider: anthropic | ollama
LLM_PROVIDER=anthropic

# Fallback provider: anthropic | ollama | mock
LLM_FALLBACK_PROVIDER=mock

# Set to true for instant mock responses (recommended for UI development)
USE_MOCK_LLM=true

# Enable fallback to secondary provider on failure
LLM_FALLBACK_ENABLED=false


# ------------------------------------------------------------------------------
# ANTHROPIC (Claude)
# ------------------------------------------------------------------------------
# Get API key: https://console.anthropic.com/
ANTHROPIC_API_KEY=
ANTHROPIC_MODEL=claude-haiku-4-5-20251001
ANTHROPIC_MAX_TOKENS=2048
ANTHROPIC_TIMEOUT=30


# ------------------------------------------------------------------------------
# OLLAMA (Local LLM)
# ------------------------------------------------------------------------------
OLLAMA_ENABLED=false
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:3b
OLLAMA_TIMEOUT=300
OLLAMA_MAX_TOKENS=1024
OLLAMA_KEEP_ALIVE=5m
# Note: For Docker, use http://host.docker.internal:11434


# ------------------------------------------------------------------------------
# VECTOR DATABASE (ChromaDB)
# ------------------------------------------------------------------------------
CHROMA_HOST=
CHROMA_PORT=8000
CHROMA_PERSIST_DIRECTORY=./chroma_data
CHROMA_COLLECTION_NAME=gita_verses


# ------------------------------------------------------------------------------
# EMBEDDINGS
# ------------------------------------------------------------------------------
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384


# ------------------------------------------------------------------------------
# RAG PIPELINE
# ------------------------------------------------------------------------------
RAG_TOP_K_VERSES=5
RAG_TOP_M_COMMENTARIES=3
RAG_CONFIDENCE_THRESHOLD=0.7
RAG_SCHOLAR_REVIEW_THRESHOLD=0.6


# ------------------------------------------------------------------------------
# CONTENT MODERATION
# ------------------------------------------------------------------------------
# Master switch to enable/disable all content filtering
CONTENT_FILTER_ENABLED=true

# Layer 1: Pre-submission blocklist (catches obvious violations before DB write)
CONTENT_FILTER_BLOCKLIST_ENABLED=true

# Layer 2: LLM refusal detection (detects when Claude refuses inappropriate content)
CONTENT_FILTER_LLM_REFUSAL_DETECTION=true


# ------------------------------------------------------------------------------
# APPLICATION
# ------------------------------------------------------------------------------
APP_ENV=development
DEBUG=true
LOG_LEVEL=INFO

# Base URL for the frontend (used in password reset emails, etc.)
FRONTEND_URL=http://localhost:5173


# ------------------------------------------------------------------------------
# API
# ------------------------------------------------------------------------------
API_V1_PREFIX=/api/v1
CORS_ORIGINS=http://localhost,http://localhost:3000,http://localhost:5173,http://127.0.0.1,http://127.0.0.1:3000,http://127.0.0.1:5173
ANALYZE_RATE_LIMIT=10/hour


# ------------------------------------------------------------------------------
# SECURITY (generate secure values for production)
# ------------------------------------------------------------------------------
# Generate: python -c "import secrets; print(secrets.token_hex(32))"

# JWT for user authentication
JWT_SECRET=dev-secret-key-change-in-production
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=10080
REFRESH_TOKEN_EXPIRE_DAYS=90

# Cookie security (set true in production, requires HTTPS)
COOKIE_SECURE=false

# Admin API key for protected endpoints (/admin/ingest, /admin/sync-featured)
API_KEY=dev-api-key-12345


# ------------------------------------------------------------------------------
# EMAIL (Resend) - for contact form
# ------------------------------------------------------------------------------
# Get API key: https://resend.com/
# All three must be set for contact form to work
RESEND_API_KEY=
CONTACT_EMAIL_TO=                    # Your email to receive contact messages
CONTACT_EMAIL_FROM=                  # Must use verified domain: Name <email@verified-domain.com>


# ------------------------------------------------------------------------------
# MONITORING (Sentry)
# ------------------------------------------------------------------------------
# Get DSN from: https://sentry.io/
# Backend and frontend can share the same project or use separate ones

# Backend Sentry DSN (Python/FastAPI)
SENTRY_DSN=

# Performance monitoring sample rate (0.0 to 1.0, default 0.1 = 10%)
SENTRY_TRACES_SAMPLE_RATE=0.1


# ------------------------------------------------------------------------------
# OBSERVABILITY (Grafana)
# ------------------------------------------------------------------------------
# Used by docker-compose.observability.yml
# Grafana dashboard: https://grafana.geetanjaliapp.com

# Grafana admin credentials
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=

# Grafana email alerts (uses Resend SMTP - same API key as contact form)
# Set GRAFANA_SMTP_ENABLED=true to enable email alerts
GRAFANA_SMTP_ENABLED=false
GRAFANA_SMTP_FROM=alerts@geetanjaliapp.com
GRAFANA_ALERT_EMAIL_TO=


# ------------------------------------------------------------------------------
# FRONTEND (Vite - only VITE_* variables are exposed to browser)
# ------------------------------------------------------------------------------
VITE_API_URL=http://localhost:8000
VITE_API_BASE_URL=
VITE_API_V1_PREFIX=/api/v1

# Frontend Analytics & Monitoring (optional)
VITE_SENTRY_DSN=
VITE_UMAMI_WEBSITE_ID=


# ==============================================================================
# PRODUCTION CHECKLIST
# ==============================================================================
# Before deploying to production, ensure:
#
# 1. [ ] Generate secure secrets:
#        python -c "import secrets; print(secrets.token_hex(32))"
#        - Set JWT_SECRET to generated value
#        - Set API_KEY to generated value
#        - Set POSTGRES_PASSWORD to secure password
#        - Set REDIS_PASSWORD to secure password
#
# 2. [ ] Configure LLM:
#        - Set USE_MOCK_LLM=false
#        - Set ANTHROPIC_API_KEY if using Claude
#        - Or configure Ollama with appropriate model
#
# 3. [ ] Set production values:
#        - APP_ENV=production
#        - DEBUG=false
#        - COOKIE_SECURE=true (requires HTTPS)
#        - LOG_LEVEL=WARNING
#
# 4. [ ] Configure CORS_ORIGINS with your domain(s)
#
# 5. [ ] Set FRONTEND_URL to your production domain
#
# 6. [ ] Configure email (optional but recommended):
#        - Set RESEND_API_KEY from https://resend.com/
#        - Set CONTACT_EMAIL_TO to your support email
#        - Set CONTACT_EMAIL_FROM with your domain
#
# 7. [ ] Configure error monitoring (recommended):
#        - Set SENTRY_DSN for backend error tracking
#        - Set VITE_SENTRY_DSN for frontend error tracking
#
# 8. [ ] Configure observability (optional but recommended):
#        - Set GRAFANA_ADMIN_PASSWORD to a secure password
#        - Deploy with: docker compose -f docker-compose.yml -f docker-compose.observability.yml up -d
#        - Access Grafana at https://grafana.geetanjaliapp.com
#
# 9. [ ] Use docker-compose.prod.yml:
#        docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
